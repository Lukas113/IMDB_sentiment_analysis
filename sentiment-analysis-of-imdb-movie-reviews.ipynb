{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"source":["**Sentiment Analysis of IMDB Movie Reviews**"]},{"cell_type":"markdown","metadata":{},"source":["**Problem Statement:**\n","\n","In this, we have to predict the number of positive and negative reviews based on sentiments by using different classification models."]},{"cell_type":"markdown","metadata":{"_uuid":"1424638f5259100af9f9a5c1b05bd23cf5b71e51"},"source":["**Import necessary libraries**"]},{"cell_type":"code","execution_count":4,"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"outputs":[],"source":["#Load the libraries\n","import numpy as np\n","import pandas as pd\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","import nltk\n","from sklearn.feature_extraction.text import CountVectorizer\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.preprocessing import LabelBinarizer\n","from nltk.corpus import stopwords\n","from nltk.tokenize.toktok import ToktokTokenizer\n","from wordcloud import WordCloud\n","from bs4 import BeautifulSoup\n","import re\n","from sklearn.linear_model import LogisticRegression,SGDClassifier\n","from sklearn.naive_bayes import MultinomialNB\n","# https://online.stat.psu.edu/stat504/lesson/1/1.7\n","from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\n","from preprocessing import preprocesser_text, binarize_sentiment, train_test_split\n","\n","import os\n","import warnings"]},{"cell_type":"markdown","metadata":{"_uuid":"be1b642cce343f7a8f68f8c91f7c50372cdf4381"},"source":["**Import the training dataset**"]},{"cell_type":"code","execution_count":2,"metadata":{"_uuid":"4c593c17588723c0b0b0f19851cb70a8447ced76","scrolled":true,"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["(50000, 2)\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>review</th>\n","      <th>sentiment</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>One of the other reviewers has mentioned that ...</td>\n","      <td>positive</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n","      <td>positive</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>I thought this was a wonderful way to spend ti...</td>\n","      <td>positive</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Basically there's a family where a little boy ...</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n","      <td>positive</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>Probably my all-time favorite movie, a story o...</td>\n","      <td>positive</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>I sure would like to see a resurrection of a u...</td>\n","      <td>positive</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>This show was an amazing, fresh &amp; innovative i...</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>Encouraged by the positive comments about this...</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>If you like original gut wrenching laughter yo...</td>\n","      <td>positive</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                              review sentiment\n","0  One of the other reviewers has mentioned that ...  positive\n","1  A wonderful little production. <br /><br />The...  positive\n","2  I thought this was a wonderful way to spend ti...  positive\n","3  Basically there's a family where a little boy ...  negative\n","4  Petter Mattei's \"Love in the Time of Money\" is...  positive\n","5  Probably my all-time favorite movie, a story o...  positive\n","6  I sure would like to see a resurrection of a u...  positive\n","7  This show was an amazing, fresh & innovative i...  negative\n","8  Encouraged by the positive comments about this...  negative\n","9  If you like original gut wrenching laughter yo...  positive"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["#importing the training data\n","imdb_data=pd.read_csv('data/IMDB Dataset.csv')\n","print(imdb_data.shape)\n","imdb_data.head(10)"]},{"cell_type":"markdown","metadata":{"_uuid":"1ad3773974351ed9bdf389b2847d7475b36c2295"},"source":["**Exploratery data analysis**"]},{"cell_type":"code","execution_count":3,"metadata":{"_uuid":"7f11c83b1320c8982b36889145f7f770563674a8","trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>review</th>\n","      <th>sentiment</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>50000</td>\n","      <td>50000</td>\n","    </tr>\n","    <tr>\n","      <th>unique</th>\n","      <td>49582</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>top</th>\n","      <td>Loved today's show!!! It was a variety and not...</td>\n","      <td>positive</td>\n","    </tr>\n","    <tr>\n","      <th>freq</th>\n","      <td>5</td>\n","      <td>25000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                                   review sentiment\n","count                                               50000     50000\n","unique                                              49582         2\n","top     Loved today's show!!! It was a variety and not...  positive\n","freq                                                    5     25000"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["#Summary of the dataset\n","imdb_data.describe()"]},{"cell_type":"markdown","metadata":{"_uuid":"453c3fd238f62ab8f649eb01771817e25bc0c77d"},"source":["**Sentiment count**"]},{"cell_type":"code","execution_count":3,"metadata":{"_uuid":"cb6bb97b0f851947dcf341a1de5708a1f2bc64c1","trusted":true},"outputs":[{"data":{"text/plain":["positive    25000\n","negative    25000\n","Name: sentiment, dtype: int64"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["#sentiment count\n","imdb_data['sentiment'].value_counts()"]},{"cell_type":"markdown","metadata":{},"source":["We can see that the dataset is balanced."]},{"cell_type":"markdown","metadata":{"_uuid":"f61964573faababe1f7897b77d32815a24954d2f"},"source":["**Spliting the training dataset**"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["Pandas Apply: 100%|██████████| 50000/50000 [00:08<00:00, 5929.06it/s]\n","Pandas Apply: 100%|██████████| 50000/50000 [00:00<00:00, 427225.56it/s]\n","Pandas Apply: 100%|██████████| 50000/50000 [03:10<00:00, 262.63it/s]\n","Pandas Apply: 100%|██████████| 50000/50000 [00:57<00:00, 870.57it/s]\n"]}],"source":["imdb_data = preprocesser_text(imdb_data)"]},{"cell_type":"markdown","metadata":{"_uuid":"90da29c3b79f46f41d7391a2a116065b616d0fac"},"source":["**Text normalization**"]},{"cell_type":"code","execution_count":20,"metadata":{"_kg_hide-output":true,"_uuid":"b20c242bd091929ca896ea2c6e936ca00efe6ecf","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["negative    20007\n","positive    19993\n","Name: sentiment, dtype: int64\n","positive    5007\n","negative    4993\n","Name: sentiment, dtype: int64\n"]},{"data":{"text/plain":["\"One of the other reviewers has mentioned that after watching just 1 Oz episode you'll be hooked. They are right, as this is exactly what happened with me.<br /><br />The first thing that struck me about Oz was its brutality and unflinching scenes of violence, which set in right from the word GO. Trust me, this is not a show for the faint hearted or timid. This show pulls no punches with regards to drugs, sex or violence. Its is hardcore, in the classic use of the word.<br /><br />It is called OZ as that is the nickname given to the Oswald Maximum Security State Penitentary. It focuses mainly on Emerald City, an experimental section of the prison where all the cells have glass fronts and face inwards, so privacy is not high on the agenda. Em City is home to many..Aryans, Muslims, gangstas, Latinos, Christians, Italians, Irish and more....so scuffles, death stares, dodgy dealings and shady agreements are never far away.<br /><br />I would say the main appeal of the show is due to the fact that it goes where other shows wouldn't dare. Forget pretty pictures painted for mainstream audiences, forget charm, forget romance...OZ doesn't mess around. The first episode I ever saw struck me as so nasty it was surreal, I couldn't say I was ready for it, but as I watched more, I developed a taste for Oz, and got accustomed to the high levels of graphic violence. Not just violence, but injustice (crooked guards who'll be sold out for a nickel, inmates who'll kill on order and get away with it, well mannered, middle class inmates being turned into prison bitches due to their lack of street skills or prison experience) Watching Oz, you may become comfortable with what is uncomfortable viewing....thats if you can get in touch with your darker side.\""]},"execution_count":20,"metadata":{},"output_type":"execute_result"}],"source":["#normalized train reviews\n","norm_train, norm_test = train_test_split(imdb_data)\n","print(norm_train.sentiment.value_counts())\n","print(norm_test.sentiment.value_counts())\n","norm_train_reviews=norm_train.review\n","norm_train_reviews[0]"]},{"cell_type":"markdown","metadata":{"_uuid":"d69462bb209a66cff86376dc8481d0c0140d894d"},"source":["**Normalized test reviews**"]},{"cell_type":"code","execution_count":16,"metadata":{"_kg_hide-output":true,"_uuid":"c5d0d38bd9976150367e9d75f3b933774c96a1ab","trusted":true},"outputs":[{"data":{"text/plain":["\"Hickory Dickory Dock was a good Poirot mystery. I confess I have not read the book, despite being an avid Agatha Christie fan. The adaptation isn't without its problems, there were times when the humour, and there were valiant attempts to get it right, was a little overdone, and the events leading up to the final solution were rather rushed. I also thought there were some slow moments so some of the mystery felt padded. However, I loved how Hickory Dickory Dock was filmed, it had a very similar visual style to the brilliant ABC Murders, and it really set the atmosphere, what with the dark camera work and dark lighting. The darker moments were somewhat creepy, this was helped by one of the most haunting music scores in a Poirot adaptation, maybe not as disturbing as the one in One Two Buckle My Shoe, which gave me nightmares. The plot is complex, with all the essential ingredients, though not as convoluted as Buckle My Shoe,and in some way that is a good thing. The acting was very good, David Suchet is impeccable(I know I can't use this word forever but I can't think of a better word to describe his performance in the series) as Poirot, and Phillip Jackson and Pauline Moran do justice to their integral characters brilliantly. And the students had great personalities and well developed on the whole, particularly Damian Lewis as Leonard. All in all, solid mystery but doesn't rank along the best. 7.5/10 Bethany Cox\""]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["#Normalized test reviews\n","norm_test_reviews=norm_test.review\n","norm_test_reviews.loc[40005]"]},{"cell_type":"markdown","metadata":{"_uuid":"52371868f05ff9cf157280c5acf0f5bc71ee176d"},"source":["**Bags of words model**\n","\n","It is used to convert text documents to numerical vectors or bag of words.\n","\n","> Convert a collection of text documents to a matrix of token counts.\n","> This implementation produces a sparse representation of the counts using scipy.sparse.csr_matrix.\n","> If you do not provide an a-priori dictionary and you do not use an analyzer that does some kind of feature selection then the number of features will be equal to the vocabulary size found by analyzing the data."]},{"cell_type":"code","execution_count":21,"metadata":{"_uuid":"35cf9dcefb40b2dc520c5b0d559695324c46cc04","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["BOW_cv_train: (40000, 6183315)\n","BOW_cv_test: (10000, 6183315)\n"]}],"source":["#Count vectorizer for bag of words\n","cv=CountVectorizer(min_df=0,max_df=1,binary=False,ngram_range=(1,3))\n","#transformed train reviews\n","cv_train_reviews=cv.fit_transform(norm_train_reviews)\n","#transformed test reviews\n","cv_test_reviews=cv.transform(norm_test_reviews)\n","\n","print('BOW_cv_train:',cv_train_reviews.shape)\n","print('BOW_cv_test:',cv_test_reviews.shape)\n","#vocab=cv.get_feature_names()-toget feature names"]},{"cell_type":"markdown","metadata":{"_uuid":"52371868f05ff9cf157280c5acf0f5bc71ee176d"},"source":["**Term Frequency-Inverse Document Frequency model (TFIDF)**\n","\n","It is used to convert text documents to  matrix of  tfidf features.\n","> The formula that is used to compute the tf-idf for a term t of a document d in a document set is tf-idf(t, d) = tf(t, d) * idf(t), and the idf is computed as idf(t) = log [ n / df(t) ] + 1 (if smooth_idf=False), where n is the total number of documents in the document set and df(t) is the document frequency of t; the document frequency is the number of documents in the document set that contain the term t. The effect of adding “1” to the idf in the equation above is that terms with zero idf, i.e., terms that occur in all documents in a training set, will not be entirely ignored. (Note that the idf formula above differs from the standard textbook notation that defines the idf as idf(t) = log [ n / (df(t) + 1) ]).\n","\n","tf(t, d) == # Wort t / max (# Wort t) über alle Dokumente\n","\n","idf(t) == # Dokumente mit Wort t / # Dokumente\n","\n","\n","tf-idf(t, d) = tf(t, d) * idf(t)"]},{"cell_type":"code","execution_count":22,"metadata":{"_uuid":"afe6de957339921e05a6faeaf731f2272fd31946","scrolled":false,"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Tfidf_train: (40000, 6183315)\n","Tfidf_test: (10000, 6183315)\n"]}],"source":["#Tfidf vectorizer\n","tv=TfidfVectorizer(min_df=0,max_df=1,use_idf=True,ngram_range=(1,3))\n","#transformed train reviews\n","tv_train_reviews=tv.fit_transform(norm_train_reviews)\n","#transformed test reviews\n","tv_test_reviews=tv.transform(norm_test_reviews)\n","print('Tfidf_train:',tv_train_reviews.shape)\n","print('Tfidf_test:',tv_test_reviews.shape)"]},{"cell_type":"markdown","metadata":{"_uuid":"803e92b25faa738b10928a91de72d177d8dddf85"},"source":["**Labeling the sentiment text**"]},{"cell_type":"markdown","metadata":{"_uuid":"21a80c94fb42e14391c627710c5d796c40aa7dde"},"source":["**Split the sentiment tdata**"]},{"cell_type":"code","execution_count":32,"metadata":{"_kg_hide-output":true,"_uuid":"ca1e4cc917265ac98a72c37cffe57f27e9897408","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["0        1\n","1        1\n","2        1\n","3        0\n","4        1\n","        ..\n","39995    1\n","39996    1\n","39997    1\n","39998    0\n","39999    0\n","Name: sentiment, Length: 40000, dtype: int64\n","40000    0\n","40001    0\n","40002    0\n","40003    0\n","40004    0\n","        ..\n","49995    1\n","49996    0\n","49997    0\n","49998    0\n","49999    0\n","Name: sentiment, Length: 10000, dtype: int64\n"]}],"source":["#Spliting the sentiment data\n","train_sentiments=norm_train.sentiment\n","test_sentiments=norm_test.sentiment\n","\n","test_sentiments = binarize_sentiment(test_sentiments)\n","train_sentiments = binarize_sentiment(train_sentiments)\n","print(train_sentiments)\n","print(test_sentiments)"]},{"cell_type":"markdown","metadata":{},"source":["**Modelling the dataset**"]},{"cell_type":"markdown","metadata":{"_uuid":"d5e45fdc9d062a5b9b9dd665ffe732776e196953"},"source":["Let us build logistic regression model for both bag of words and tfidf features"]},{"cell_type":"code","execution_count":33,"metadata":{"_uuid":"142d007421900550079a12ae8655bcae678ebaad","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["LogisticRegression(C=1, max_iter=500, random_state=42)\n","LogisticRegression(C=1, max_iter=500, random_state=42)\n"]}],"source":["#training the model\n","lr=LogisticRegression(penalty='l2',max_iter=500,C=1,random_state=42)\n","#Fitting the model for Bag of words\n","lr_bow=lr.fit(cv_train_reviews,train_sentiments)\n","print(lr_bow)\n","#Fitting the model for tfidf features\n","lr_tfidf=lr.fit(tv_train_reviews,train_sentiments)\n","print(lr_tfidf)"]},{"cell_type":"markdown","metadata":{"_uuid":"07eb6d52eb32469e3be82e90af636d598a7b7c27"},"source":["**Logistic regression model performane on test dataset**"]},{"cell_type":"code","execution_count":34,"metadata":{"_uuid":"52ad86935b76117f97b79e6672a3ba12352b9461","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["[0 0 0 ... 0 0 0]\n","[0 0 0 ... 0 0 0]\n"]}],"source":["#Predicting the model for bag of words\n","lr_bow_predict=lr.predict(cv_test_reviews)\n","print(lr_bow_predict)\n","##Predicting the model for tfidf features\n","lr_tfidf_predict=lr.predict(tv_test_reviews)\n","print(lr_tfidf_predict)"]},{"cell_type":"markdown","metadata":{},"source":["**Accuracy of the model**"]},{"cell_type":"code","execution_count":35,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["lr_bow_score : 0.7676\n","lr_tfidf_score : 0.7659\n"]}],"source":["#Accuracy score for bag of words\n","lr_bow_score=accuracy_score(test_sentiments,lr_bow_predict)\n","print(\"lr_bow_score :\",lr_bow_score)\n","#Accuracy score for tfidf features\n","lr_tfidf_score=accuracy_score(test_sentiments,lr_tfidf_predict)\n","print(\"lr_tfidf_score :\",lr_tfidf_score)"]},{"cell_type":"markdown","metadata":{"_uuid":"ac2ec8353acb5e0f548e1e4a590fbe6f34f4a686"},"source":["**Print the classification report**"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"f89c7e7a6136d08790ffbf6bc4d0d05455f8555a","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","    Positive       0.75      0.75      0.75      4993\n","    Negative       0.75      0.75      0.75      5007\n","\n","    accuracy                           0.75     10000\n","   macro avg       0.75      0.75      0.75     10000\n","weighted avg       0.75      0.75      0.75     10000\n","\n","              precision    recall  f1-score   support\n","\n","    Positive       0.74      0.77      0.75      4993\n","    Negative       0.76      0.73      0.75      5007\n","\n","    accuracy                           0.75     10000\n","   macro avg       0.75      0.75      0.75     10000\n","weighted avg       0.75      0.75      0.75     10000\n","\n"]}],"source":["#Classification report for bag of words \n","lr_bow_report=classification_report(test_sentiments,lr_bow_predict,target_names=['Positive','Negative'])\n","print(lr_bow_report)\n","\n","#Classification report for tfidf features\n","lr_tfidf_report=classification_report(test_sentiments,lr_tfidf_predict,target_names=['Positive','Negative'])\n","print(lr_tfidf_report)"]},{"cell_type":"markdown","metadata":{"_uuid":"0d2e5ddcd69ff0fb52f05f17fc74a86e1b5e5b61"},"source":["**Confusion matrix**"]},{"cell_type":"code","execution_count":36,"metadata":{"_uuid":"a36c058e834938559b7202f2142e61423a613b7a","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["[[3845 1162]\n"," [1162 3831]]\n","[[3743 1264]\n"," [1077 3916]]\n"]}],"source":["#confusion matrix for bag of words\n","cm_bow=confusion_matrix(test_sentiments,lr_bow_predict,labels=[1,0])\n","print(cm_bow)\n","#confusion matrix for tfidf features\n","cm_tfidf=confusion_matrix(test_sentiments,lr_tfidf_predict,labels=[1,0])\n","print(cm_tfidf)"]},{"cell_type":"markdown","metadata":{"_uuid":"8fde9753386e3593dc27c4e88e02bdc38462a018"},"source":["**Stochastic gradient descent or Linear support vector machines for bag of words and tfidf features**"]},{"cell_type":"code","execution_count":37,"metadata":{"_uuid":"2211a9e97682195a0372b33e4da7267aad8548db","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["SGDClassifier(max_iter=500, random_state=42)\n","SGDClassifier(max_iter=500, random_state=42)\n"]}],"source":["#training the linear svm\n","svm=SGDClassifier(loss='hinge',max_iter=500,random_state=42)\n","#fitting the svm for bag of words\n","svm_bow=svm.fit(cv_train_reviews,train_sentiments)\n","print(svm_bow)\n","#fitting the svm for tfidf features\n","svm_tfidf=svm.fit(tv_train_reviews,train_sentiments)\n","print(svm_tfidf)"]},{"cell_type":"markdown","metadata":{"_uuid":"e9a7a973591c1d3cabaa1a47c57fa029d3752bab"},"source":["**Model performance on test data**"]},{"cell_type":"code","execution_count":38,"metadata":{"_uuid":"1a5ab738e04f0f9082c8d6ade6c2148cc398f8f3","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["[1 0 1 ... 1 1 1]\n","[1 1 1 ... 1 1 1]\n"]}],"source":["#Predicting the model for bag of words\n","svm_bow_predict=svm.predict(cv_test_reviews)\n","print(svm_bow_predict)\n","#Predicting the model for tfidf features\n","svm_tfidf_predict=svm.predict(tv_test_reviews)\n","print(svm_tfidf_predict)"]},{"cell_type":"markdown","metadata":{},"source":["**Accuracy of the model**"]},{"cell_type":"code","execution_count":39,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["svm_bow_score : 0.6383\n","svm_tfidf_score : 0.5111\n"]}],"source":["#Accuracy score for bag of words\n","svm_bow_score=accuracy_score(test_sentiments,svm_bow_predict)\n","print(\"svm_bow_score :\",svm_bow_score)\n","#Accuracy score for tfidf features\n","svm_tfidf_score=accuracy_score(test_sentiments,svm_tfidf_predict)\n","print(\"svm_tfidf_score :\",svm_tfidf_score)"]},{"cell_type":"markdown","metadata":{"_uuid":"b1bd245f50902ad87ca28e48cbce64ec6a16ec5a"},"source":["**Print the classification report**"]},{"cell_type":"code","execution_count":40,"metadata":{"_uuid":"d112bc5b4944330b567e19a7e04544a9a459f238","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","    Positive       0.93      0.30      0.45      4993\n","    Negative       0.58      0.98      0.73      5007\n","\n","    accuracy                           0.64     10000\n","   macro avg       0.76      0.64      0.59     10000\n","weighted avg       0.76      0.64      0.59     10000\n","\n","              precision    recall  f1-score   support\n","\n","    Positive       1.00      0.02      0.04      4993\n","    Negative       0.51      1.00      0.67      5007\n","\n","    accuracy                           0.51     10000\n","   macro avg       0.75      0.51      0.36     10000\n","weighted avg       0.75      0.51      0.36     10000\n","\n"]}],"source":["#Classification report for bag of words \n","svm_bow_report=classification_report(test_sentiments,svm_bow_predict,target_names=['Positive','Negative'])\n","print(svm_bow_report)\n","#Classification report for tfidf features\n","svm_tfidf_report=classification_report(test_sentiments,svm_tfidf_predict,target_names=['Positive','Negative'])\n","print(svm_tfidf_report)"]},{"cell_type":"markdown","metadata":{"_uuid":"705fd8ae8bb5e6925852fffc906b6ffd769dbac0"},"source":["**Plot the confusion matrix**"]},{"cell_type":"code","execution_count":41,"metadata":{"_uuid":"49cde912705acbaef90d7a269cd27ea8a2815f03","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["[[4901  106]\n"," [3511 1482]]\n","[[5007    0]\n"," [4889  104]]\n"]}],"source":["#confusion matrix for bag of words\n","cm_bow=confusion_matrix(test_sentiments,svm_bow_predict,labels=[1,0])\n","print(cm_bow)\n","#confusion matrix for tfidf features\n","cm_tfidf=confusion_matrix(test_sentiments,svm_tfidf_predict,labels=[1,0])\n","print(cm_tfidf)"]},{"cell_type":"markdown","metadata":{},"source":["**Multinomial Naive Bayes for bag of words and tfidf features**"]},{"cell_type":"code","execution_count":42,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["MultinomialNB()\n","MultinomialNB()\n"]}],"source":["#training the model\n","mnb=MultinomialNB()\n","#fitting the svm for bag of words\n","mnb_bow=mnb.fit(cv_train_reviews,train_sentiments)\n","print(mnb_bow)\n","#fitting the svm for tfidf features\n","mnb_tfidf=mnb.fit(tv_train_reviews,train_sentiments)\n","print(mnb_tfidf)"]},{"cell_type":"markdown","metadata":{},"source":["**Model performance on test data**"]},{"cell_type":"code","execution_count":43,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["[0 0 0 ... 0 0 0]\n","[0 0 0 ... 0 0 0]\n"]}],"source":["#Predicting the model for bag of words\n","mnb_bow_predict=mnb.predict(cv_test_reviews)\n","print(mnb_bow_predict)\n","#Predicting the model for tfidf features\n","mnb_tfidf_predict=mnb.predict(tv_test_reviews)\n","print(mnb_tfidf_predict)"]},{"cell_type":"markdown","metadata":{},"source":["**Accuracy of the model**"]},{"cell_type":"code","execution_count":44,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["mnb_bow_score : 0.7682\n","mnb_tfidf_score : 0.7677\n"]}],"source":["#Accuracy score for bag of words\n","mnb_bow_score=accuracy_score(test_sentiments,mnb_bow_predict)\n","print(\"mnb_bow_score :\",mnb_bow_score)\n","#Accuracy score for tfidf features\n","mnb_tfidf_score=accuracy_score(test_sentiments,mnb_tfidf_predict)\n","print(\"mnb_tfidf_score :\",mnb_tfidf_score)"]},{"cell_type":"markdown","metadata":{},"source":["**Print the classification report**"]},{"cell_type":"code","execution_count":45,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","    Positive       0.76      0.78      0.77      4993\n","    Negative       0.77      0.76      0.77      5007\n","\n","    accuracy                           0.77     10000\n","   macro avg       0.77      0.77      0.77     10000\n","weighted avg       0.77      0.77      0.77     10000\n","\n","              precision    recall  f1-score   support\n","\n","    Positive       0.76      0.78      0.77      4993\n","    Negative       0.77      0.76      0.77      5007\n","\n","    accuracy                           0.77     10000\n","   macro avg       0.77      0.77      0.77     10000\n","weighted avg       0.77      0.77      0.77     10000\n","\n"]}],"source":["#Classification report for bag of words \n","mnb_bow_report=classification_report(test_sentiments,mnb_bow_predict,target_names=['Positive','Negative'])\n","print(mnb_bow_report)\n","#Classification report for tfidf features\n","mnb_tfidf_report=classification_report(test_sentiments,mnb_tfidf_predict,target_names=['Positive','Negative'])\n","print(mnb_tfidf_report)"]},{"cell_type":"markdown","metadata":{},"source":["**Plot the confusion matrix**"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["[[3736 1271]\n"," [1219 3774]]\n","[[3729 1278]\n"," [1213 3780]]\n"]}],"source":["#confusion matrix for bag of words\n","cm_bow=confusion_matrix(test_sentiments,mnb_bow_predict,labels=[1,0])\n","print(cm_bow)\n","#confusion matrix for tfidf features\n","cm_tfidf=confusion_matrix(test_sentiments,mnb_tfidf_predict,labels=[1,0])\n","print(cm_tfidf)"]},{"cell_type":"markdown","metadata":{},"source":[]}],"metadata":{"interpreter":{"hash":"c1eac46bfc9221687887cfb6dac019e54e452a3a6e2b82ef73adb9c089464026"},"kernelspec":{"display_name":"Python 3.8.11 64-bit ('npr': conda)","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.11"}},"nbformat":4,"nbformat_minor":1}
